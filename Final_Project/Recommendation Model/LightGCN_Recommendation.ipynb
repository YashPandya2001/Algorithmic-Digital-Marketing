{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate reco_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Algorithmic Marketing\\Assignment 3\\recommenders\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Algorithmic Marketing\\Assignment 3\\recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "Pandas version: 1.0.5\n",
      "Tensorflow version: 1.15.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import pickle\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.recommender.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from reco_utils.recommender.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from reco_utils.common.constants import SEED as DEFAULT_SEED\n",
    "from reco_utils.recommender.deeprec.deeprec_utils import prepare_hparams\n",
    "\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "ALIBABA_DATA_SIZE = '100k'\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "SEED = DEFAULT_SEED  # Set None for non-deterministic results\n",
    "\n",
    "yaml_file = \"D:/Algorithmic Marketing/Assignment 3/recommenders/reco_utils/recommender/deeprec/config/lightgcn.yaml\"\n",
    "user_file = \"../../tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "item_file = \"../../tests/resources/deeprec/lightgcn/item_embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Algorithmic Marketing/Final Project/Dataset/Recommendation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>85123A</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17850</td>\n",
       "      <td>71053</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17850</td>\n",
       "      <td>84406B</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17850</td>\n",
       "      <td>84029G</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17850</td>\n",
       "      <td>84029E</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0   17850  85123A       8\n",
       "1   17850   71053       7\n",
       "2   17850  84406B       8\n",
       "3   17850  84029G       5\n",
       "4   17850  84029E       9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImplicitCF(train=train, test=test, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          n_layers=3,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          learning_rate=0.005,\n",
    "                          eval_epoch=5,\n",
    "                          top_k=TOP_K,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:37: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:68: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Using xavier initialization.\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:147: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:104: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\DataModel\\ImplicitCF.py:179: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:105: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:107: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:108: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:108: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Algorithmic Marketing\\Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:109: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(hparams, data, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( model, open( \"LGCN_model.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)2.7s: train loss = 0.58990 = (mf)0.58975 + (embed)0.00015\n",
      "Epoch 2 (train)2.4s: train loss = 0.38810 = (mf)0.38742 + (embed)0.00067\n",
      "Epoch 3 (train)2.3s: train loss = 0.33910 = (mf)0.33811 + (embed)0.00099\n",
      "Epoch 4 (train)2.2s: train loss = 0.29073 = (mf)0.28941 + (embed)0.00133\n",
      "Epoch 5 (train)2.3s + (eval)0.3s: train loss = 0.25533 = (mf)0.25363 + (embed)0.00170, recall = 0.03931, ndcg = 0.05804, precision = 0.04450, map = 0.01551\n",
      "Epoch 6 (train)2.3s: train loss = 0.22173 = (mf)0.21965 + (embed)0.00208\n",
      "Epoch 7 (train)2.3s: train loss = 0.19596 = (mf)0.19351 + (embed)0.00245\n",
      "Epoch 8 (train)2.3s: train loss = 0.17456 = (mf)0.17174 + (embed)0.00282\n",
      "Epoch 9 (train)2.3s: train loss = 0.15914 = (mf)0.15597 + (embed)0.00317\n",
      "Epoch 10 (train)2.3s + (eval)0.2s: train loss = 0.14731 = (mf)0.14381 + (embed)0.00350, recall = 0.05986, ndcg = 0.08540, precision = 0.06323, map = 0.02454\n",
      "Epoch 11 (train)2.3s: train loss = 0.13399 = (mf)0.13016 + (embed)0.00383\n",
      "Epoch 12 (train)2.3s: train loss = 0.12441 = (mf)0.12027 + (embed)0.00414\n",
      "Epoch 13 (train)2.5s: train loss = 0.11218 = (mf)0.10773 + (embed)0.00445\n",
      "Epoch 14 (train)2.2s: train loss = 0.10349 = (mf)0.09875 + (embed)0.00474\n",
      "Epoch 15 (train)2.3s + (eval)0.2s: train loss = 0.09968 = (mf)0.09466 + (embed)0.00502, recall = 0.06731, ndcg = 0.09843, precision = 0.07113, map = 0.02917\n",
      "Epoch 16 (train)2.3s: train loss = 0.09229 = (mf)0.08701 + (embed)0.00528\n",
      "Epoch 17 (train)2.3s: train loss = 0.08753 = (mf)0.08198 + (embed)0.00555\n",
      "Epoch 18 (train)2.2s: train loss = 0.08213 = (mf)0.07633 + (embed)0.00581\n",
      "Epoch 19 (train)2.5s: train loss = 0.07572 = (mf)0.06967 + (embed)0.00605\n",
      "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.07241 = (mf)0.06613 + (embed)0.00629, recall = 0.07392, ndcg = 0.10331, precision = 0.07526, map = 0.03162\n",
      "Epoch 21 (train)2.2s: train loss = 0.07044 = (mf)0.06394 + (embed)0.00650\n",
      "Epoch 22 (train)2.3s: train loss = 0.06486 = (mf)0.05815 + (embed)0.00671\n",
      "Epoch 23 (train)2.2s: train loss = 0.06376 = (mf)0.05685 + (embed)0.00692\n",
      "Epoch 24 (train)2.3s: train loss = 0.05930 = (mf)0.05218 + (embed)0.00712\n",
      "Epoch 25 (train)2.2s + (eval)0.2s: train loss = 0.05648 = (mf)0.04916 + (embed)0.00731, recall = 0.08036, ndcg = 0.11110, precision = 0.08162, map = 0.03418\n",
      "Epoch 26 (train)2.3s: train loss = 0.05606 = (mf)0.04858 + (embed)0.00748\n",
      "Epoch 27 (train)2.2s: train loss = 0.05259 = (mf)0.04492 + (embed)0.00767\n",
      "Epoch 28 (train)2.2s: train loss = 0.05082 = (mf)0.04299 + (embed)0.00782\n",
      "Epoch 29 (train)2.4s: train loss = 0.05067 = (mf)0.04268 + (embed)0.00799\n",
      "Epoch 30 (train)2.5s + (eval)0.2s: train loss = 0.04777 = (mf)0.03963 + (embed)0.00815, recall = 0.08617, ndcg = 0.11930, precision = 0.08763, map = 0.03786\n",
      "Epoch 31 (train)2.4s: train loss = 0.04605 = (mf)0.03775 + (embed)0.00830\n",
      "Epoch 32 (train)2.2s: train loss = 0.04580 = (mf)0.03734 + (embed)0.00845\n",
      "Epoch 33 (train)2.5s: train loss = 0.04377 = (mf)0.03518 + (embed)0.00859\n",
      "Epoch 34 (train)2.4s: train loss = 0.04263 = (mf)0.03390 + (embed)0.00872\n",
      "Epoch 35 (train)2.8s + (eval)0.3s: train loss = 0.04231 = (mf)0.03346 + (embed)0.00885, recall = 0.08657, ndcg = 0.12088, precision = 0.08780, map = 0.03923\n",
      "Epoch 36 (train)3.5s: train loss = 0.04155 = (mf)0.03259 + (embed)0.00897\n",
      "Epoch 37 (train)3.0s: train loss = 0.03988 = (mf)0.03080 + (embed)0.00908\n",
      "Epoch 38 (train)2.4s: train loss = 0.03865 = (mf)0.02944 + (embed)0.00921\n",
      "Epoch 39 (train)2.8s: train loss = 0.03800 = (mf)0.02868 + (embed)0.00932\n",
      "Epoch 40 (train)2.6s + (eval)0.3s: train loss = 0.03707 = (mf)0.02764 + (embed)0.00943, recall = 0.08850, ndcg = 0.12210, precision = 0.08780, map = 0.03941\n",
      "Epoch 41 (train)2.7s: train loss = 0.03763 = (mf)0.02809 + (embed)0.00954\n",
      "Epoch 42 (train)2.5s: train loss = 0.03707 = (mf)0.02745 + (embed)0.00962\n",
      "Epoch 43 (train)2.5s: train loss = 0.03592 = (mf)0.02619 + (embed)0.00973\n",
      "Epoch 44 (train)2.3s: train loss = 0.03439 = (mf)0.02456 + (embed)0.00983\n",
      "Epoch 45 (train)2.7s + (eval)0.3s: train loss = 0.03406 = (mf)0.02412 + (embed)0.00994, recall = 0.08719, ndcg = 0.12293, precision = 0.08797, map = 0.04022\n",
      "Epoch 46 (train)2.7s: train loss = 0.03200 = (mf)0.02199 + (embed)0.01001\n",
      "Epoch 47 (train)2.4s: train loss = 0.03324 = (mf)0.02314 + (embed)0.01010\n",
      "Epoch 48 (train)2.3s: train loss = 0.03188 = (mf)0.02169 + (embed)0.01019\n",
      "Epoch 49 (train)2.3s: train loss = 0.03215 = (mf)0.02188 + (embed)0.01027\n",
      "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 0.03107 = (mf)0.02072 + (embed)0.01035, recall = 0.09079, ndcg = 0.12464, precision = 0.08866, map = 0.04102\n",
      "Took 123.0679513 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit()\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12349</td>\n",
       "      <td>23245</td>\n",
       "      <td>8.174675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12349</td>\n",
       "      <td>22839</td>\n",
       "      <td>7.465651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12349</td>\n",
       "      <td>22423</td>\n",
       "      <td>7.303855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349</td>\n",
       "      <td>23284</td>\n",
       "      <td>6.950679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12349</td>\n",
       "      <td>22507</td>\n",
       "      <td>6.786175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID itemID  prediction\n",
       "0   12349  23245    8.174675\n",
       "1   12349  22839    7.465651\n",
       "2   12349  22423    7.303855\n",
       "3   12349  23284    6.950679\n",
       "4   12349  22507    6.786175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_scores = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "topk_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.041018\n",
      "NDCG:\t0.124642\n",
      "Precision@K:\t0.088660\n",
      "Recall@K:\t0.090790\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_precision = precision_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.record(\"map\", eval_map)\n",
    "pm.record(\"ndcg\", eval_ndcg)\n",
    "pm.record(\"precision\", eval_precision)\n",
    "pm.record(\"recall\", eval_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infer_embedding(user_file, item_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verle\\Assignment_3_Recommendation\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\verle\\Assignment_3_Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightGCN.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'LightGCN.sav'\n",
    "joblib.dump(topk_scores, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
