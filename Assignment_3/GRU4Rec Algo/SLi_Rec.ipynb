{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-RRduiEPr1mc",
    "outputId": "e733671c-9c2b-4748-a193-c6c2074f1a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ADM Assignment 3\\recommenders\n"
     ]
    }
   ],
   "source": [
    "cd D:\\ADM Assignment 3\\recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JhSlHjw3r_NF",
    "outputId": "16659d32-9549-4765-c5d5-943e150507fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Tensorflow version: 1.15.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import logging\n",
    "import papermill as pm\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from reco_utils.common.constants import SEED\n",
    "from reco_utils.recommender.deeprec.deeprec_utils import (\n",
    "    prepare_hparams\n",
    ")\n",
    "from reco_utils.dataset.amazon_reviews import download_and_extract, data_preprocessing\n",
    "from reco_utils.dataset.download_utils import maybe_download\n",
    "#from reco_utils.recommender.deeprec.models.sequential.sli_rec import SLI_RECModel\n",
    "####  to use the other model, use one of the following lines:\n",
    "#from reco_utils.recommender.deeprec.models.sequential.asvd import A2SVDModel\n",
    "#from reco_utils.recommender.deeprec.models.sequential.caser import CaserModel\n",
    "from reco_utils.recommender.deeprec.models.sequential.gru4rec import GRU4RecModel\n",
    "#from reco_utils.recommender.deeprec.models.sequential.nextitnet import NextItNetModel\n",
    "\n",
    "from reco_utils.recommender.deeprec.io.sequential_iterator import SequentialIterator\n",
    "#from reco_utils.recommender.deeprec.io.nextitnet_iterator import NextItNetIterator\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIP46C_qhbR9"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 400\n",
    "RANDOM_SEED = SEED  # Set None for non-deterministic result\n",
    "yaml_file = 'D://ADM Assignment 3//recommenders//reco_utils//recommender//deeprec//config//sli_rec.yaml'\n",
    "data_path = 'D://ADM Assignment 3//recommenders//tests//resources//deeprec//slirec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSqH6p0ghfax"
   },
   "outputs": [],
   "source": [
    "# for test\n",
    "train_file = os.path.join(data_path, r'train_data')\n",
    "valid_file = os.path.join(data_path, r'valid_data')\n",
    "test_file = os.path.join(data_path, r'test_data')\n",
    "user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n",
    "item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n",
    "cate_vocab = os.path.join(data_path, r'category_vocab.pkl')\n",
    "output_file = os.path.join(data_path, r'output.txt')\n",
    "\n",
    "user_name = 'D://ADM Assignment 3//recommenders//Assignment3//user.csv'\n",
    "snack_name = 'D://ADM Assignment 3//recommenders//Assignment3//product.csv'\n",
    "reviews_file = os.path.join(data_path, snack_name)\n",
    "user_file = os.path.join(data_path, user_name)\n",
    "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
    "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
    "test_num_ngs = 9 # number of negative instances with a positive instance for testing\n",
    "sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n",
    "\n",
    "input_files = [reviews_file, meta_file, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    download_and_extract(reviews_name, reviews_file)\n",
    "    download_and_extract(meta_name, meta_file)\n",
    "    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n",
    "    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n",
    "    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKMkc_b5jsP3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hparams = prepare_hparams(yaml_file, \n",
    "                          embed_l2=0., \n",
    "                          layer_l2=0., \n",
    "                          learning_rate=0.001, \n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          show_step=20,\n",
    "                          MODEL_DIR=os.path.join(data_path, \"model/\"),\n",
    "                          SUMMARIES_DIR=os.path.join(data_path, \"summary/\"),\n",
    "                          user_vocab=user_vocab,\n",
    "                          item_vocab=item_vocab,\n",
    "                          cate_vocab=cate_vocab,\n",
    "                          need_sample=True,\n",
    "                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAbs6067kbiC"
   },
   "outputs": [],
   "source": [
    "input_creator = SequentialIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AvOYLyW5CRd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:43: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:28: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:64: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:249: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:271: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:334: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\gru4rec.py:69: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\gru4rec.py:73: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\YashPandya\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\YashPandya\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\YashPandya\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\YashPandya\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:669: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From C:\\Users\\YashPandya\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:341: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:57: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:57: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:58: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:107: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:110: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:62: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:63: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\base_model.py:64: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GRU4RecModel(hparams, input_creator, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vdE7AsglEwX-",
    "outputId": "037364c6-01a9-4b72-8001-3e23509d1e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.4979, 'logloss': 0.6931, 'mean_mrr': 0.2781, 'ndcg@2': 0.1473, 'ndcg@4': 0.2339, 'ndcg@6': 0.3075, 'group_auc': 0.4989}\n"
     ]
    }
   ],
   "source": [
    "print(model.run_eval(test_file, num_ngs=test_num_ngs)) # test_num_ngs is the number of negative lines after each positive line in your test_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "k4p-yczBNd2O",
    "outputId": "3d63fac9-5cdd-4c58-b67c-418123a70431",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:105: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "step 20 , total_loss: 1.6118, data_loss: 1.6118\n",
      "step 40 , total_loss: 1.6072, data_loss: 1.6072\n",
      "eval valid at epoch 1: auc:0.5267,logloss:0.6932,mean_mrr:0.4771,ndcg@2:0.3548,ndcg@4:0.5368,ndcg@6:0.6055,group_auc:0.5292\n",
      "step 20 , total_loss: 1.5007, data_loss: 1.5007\n",
      "step 40 , total_loss: 1.4153, data_loss: 1.4153\n",
      "eval valid at epoch 2: auc:0.6676,logloss:0.7269,mean_mrr:0.5864,ndcg@2:0.5095,ndcg@4:0.6581,ndcg@6:0.6894,group_auc:0.6666\n",
      "step 20 , total_loss: 1.4515, data_loss: 1.4515\n",
      "step 40 , total_loss: 1.3260, data_loss: 1.3260\n",
      "eval valid at epoch 3: auc:0.6998,logloss:0.8063,mean_mrr:0.6124,ndcg@2:0.5484,ndcg@4:0.6803,ndcg@6:0.7092,group_auc:0.6928\n",
      "step 20 , total_loss: 1.2797, data_loss: 1.2797\n",
      "step 40 , total_loss: 1.3882, data_loss: 1.3882\n",
      "eval valid at epoch 4: auc:0.7082,logloss:0.6688,mean_mrr:0.623,ndcg@2:0.5607,ndcg@4:0.6877,ndcg@6:0.7171,group_auc:0.6998\n",
      "step 20 , total_loss: 1.3661, data_loss: 1.3661\n",
      "step 40 , total_loss: 1.2706, data_loss: 1.2706\n",
      "eval valid at epoch 5: auc:0.7101,logloss:0.6267,mean_mrr:0.6278,ndcg@2:0.5649,ndcg@4:0.6916,ndcg@6:0.7206,group_auc:0.702\n",
      "step 20 , total_loss: 1.2522, data_loss: 1.2522\n",
      "step 40 , total_loss: 1.2190, data_loss: 1.2190\n",
      "eval valid at epoch 6: auc:0.7116,logloss:0.6452,mean_mrr:0.6299,ndcg@2:0.5696,ndcg@4:0.6932,ndcg@6:0.7223,group_auc:0.7048\n",
      "step 20 , total_loss: 1.2829, data_loss: 1.2829\n",
      "step 40 , total_loss: 1.2551, data_loss: 1.2551\n",
      "eval valid at epoch 7: auc:0.7135,logloss:0.6581,mean_mrr:0.6322,ndcg@2:0.5719,ndcg@4:0.6965,ndcg@6:0.724,group_auc:0.7071\n",
      "step 20 , total_loss: 1.2480, data_loss: 1.2480\n",
      "step 40 , total_loss: 1.2652, data_loss: 1.2652\n",
      "eval valid at epoch 8: auc:0.7165,logloss:0.653,mean_mrr:0.6304,ndcg@2:0.5717,ndcg@4:0.6943,ndcg@6:0.7226,group_auc:0.7059\n",
      "step 20 , total_loss: 1.1967, data_loss: 1.1967\n",
      "step 40 , total_loss: 1.3121, data_loss: 1.3121\n",
      "eval valid at epoch 9: auc:0.7156,logloss:0.68,mean_mrr:0.6372,ndcg@2:0.5768,ndcg@4:0.6996,ndcg@6:0.7277,group_auc:0.7112\n",
      "step 20 , total_loss: 1.2216, data_loss: 1.2216\n",
      "step 40 , total_loss: 1.2798, data_loss: 1.2798\n",
      "eval valid at epoch 10: auc:0.716,logloss:0.6542,mean_mrr:0.6332,ndcg@2:0.5723,ndcg@4:0.6955,ndcg@6:0.7247,group_auc:0.7064\n",
      "[(1, {'auc': 0.5267, 'logloss': 0.6932, 'mean_mrr': 0.4771, 'ndcg@2': 0.3548, 'ndcg@4': 0.5368, 'ndcg@6': 0.6055, 'group_auc': 0.5292}), (2, {'auc': 0.6676, 'logloss': 0.7269, 'mean_mrr': 0.5864, 'ndcg@2': 0.5095, 'ndcg@4': 0.6581, 'ndcg@6': 0.6894, 'group_auc': 0.6666}), (3, {'auc': 0.6998, 'logloss': 0.8063, 'mean_mrr': 0.6124, 'ndcg@2': 0.5484, 'ndcg@4': 0.6803, 'ndcg@6': 0.7092, 'group_auc': 0.6928}), (4, {'auc': 0.7082, 'logloss': 0.6688, 'mean_mrr': 0.623, 'ndcg@2': 0.5607, 'ndcg@4': 0.6877, 'ndcg@6': 0.7171, 'group_auc': 0.6998}), (5, {'auc': 0.7101, 'logloss': 0.6267, 'mean_mrr': 0.6278, 'ndcg@2': 0.5649, 'ndcg@4': 0.6916, 'ndcg@6': 0.7206, 'group_auc': 0.702}), (6, {'auc': 0.7116, 'logloss': 0.6452, 'mean_mrr': 0.6299, 'ndcg@2': 0.5696, 'ndcg@4': 0.6932, 'ndcg@6': 0.7223, 'group_auc': 0.7048}), (7, {'auc': 0.7135, 'logloss': 0.6581, 'mean_mrr': 0.6322, 'ndcg@2': 0.5719, 'ndcg@4': 0.6965, 'ndcg@6': 0.724, 'group_auc': 0.7071}), (8, {'auc': 0.7165, 'logloss': 0.653, 'mean_mrr': 0.6304, 'ndcg@2': 0.5717, 'ndcg@4': 0.6943, 'ndcg@6': 0.7226, 'group_auc': 0.7059}), (9, {'auc': 0.7156, 'logloss': 0.68, 'mean_mrr': 0.6372, 'ndcg@2': 0.5768, 'ndcg@4': 0.6996, 'ndcg@6': 0.7277, 'group_auc': 0.7112}), (10, {'auc': 0.716, 'logloss': 0.6542, 'mean_mrr': 0.6332, 'ndcg@2': 0.5723, 'ndcg@4': 0.6955, 'ndcg@6': 0.7247, 'group_auc': 0.7064})]\n",
      "best epoch: 9\n",
      "Time cost for training is 5.50 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n",
    "# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n",
    "# we will evaluate the performance of model on valid_file every epoch\n",
    "end_time = time.time()\n",
    "print('Time cost for training is {0:.2f} mins'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "FNKqMxaQmbqm",
    "outputId": "1e030667-3960-41ea-db76-bf44a72f9333",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.688, 'logloss': 0.6787, 'mean_mrr': 0.4434, 'ndcg@2': 0.3423, 'ndcg@4': 0.4568, 'ndcg@6': 0.5138, 'group_auc': 0.6794}\n"
     ]
    }
   ],
   "source": [
    "res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"res_syn\", res_syn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZxVkgNsMoG0h",
    "outputId": "985562c4-8ea8-4643-c699-00b1f3b7819c"
   },
   "source": [
    "model_file = model.predict(test_file, output_file)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRU4Rec.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'GRU4Rec.sav'\n",
    "joblib.dump(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YashPandya\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\sequential\\sequential_base_model.py:227: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "<reco_utils.recommender.deeprec.models.sequential.gru4rec.GRU4RecModel object at 0x000002284AD7A7C8>\n"
     ]
    }
   ],
   "source": [
    "model_file = model.predict(test_file, output_file)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SLi_Rec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
